{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import os\n",
    "import os\n",
    "import sys\n",
    "\n",
    "## CHANGE THIS\n",
    "dir2 = os.path.abspath(\"/volume/Orion/orion\")\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path:\n",
    "    sys.path.append(dir1)\n",
    "import importlib\n",
    "\n",
    "importlib.util.find_spec(\"orion\")\n",
    "# import torch\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.core.display import HTML, display\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "pd.set_option(\"display.max_columns\", 250)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "pd.set_option(\"display.max_colwidth\", 300)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_threads = 24\n",
    "os.environ[\"OMP_NUM_THREADS\"] = str(num_threads)\n",
    "os.environ[\"MKL_NUM_THREADS\"] = str(num_threads)\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = str(num_threads)\n",
    "import torch\n",
    "\n",
    "# torch.set_float32_matmul_precision(\"high\")\n",
    "torch.set_num_threads(num_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_stats(df):\n",
    "    from tabulate import tabulate\n",
    "\n",
    "    print(\"\\n***** Shape: \", df.shape, \" *****\\n\")\n",
    "\n",
    "    df_stat_val = pd.DataFrame({\n",
    "        \"Name\": df.columns,\n",
    "        \"Null\": df.isnull().sum(),\n",
    "        \"Unique\": df.nunique(),\n",
    "        \"Dtypes\": df.dtypes\n",
    "    })\n",
    "\n",
    "    print(tabulate(df_stat_val, headers=\"keys\", tablefmt=\"psql\"))\n",
    "    return df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['NCCL_P2P_DISABLE'] = '1'\n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models.video\n",
    "from pytorchvideo.models.x3d import create_x3d\n",
    "import sys\n",
    "\n",
    "## CHANGE THIS\n",
    "dir2 = os.path.abspath(\"/volume/Orion/orion\")\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path:\n",
    "    sys.path.append(dir1)\n",
    "import importlib\n",
    "\n",
    "model = create_x3d()\n",
    "display(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "## CHANGE THIS\n",
    "dir2 = os.path.abspath(\"/volume/Orion/orion\")\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path:\n",
    "    sys.path.append(dir1)\n",
    "import importlib\n",
    "\n",
    "importlib.util.find_spec(\"orion\")\n",
    "\n",
    "\n",
    "dir2 = os.path.abspath(\"/volume/Orion/orion\")\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path:\n",
    "    sys.path.append(dir1)\n",
    "import importlib\n",
    "\n",
    "importlib.util.find_spec(\"orion\")\n",
    "# import torch\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.core.display import HTML, display\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "pd.set_option(\"display.max_colwidth\", 300)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "torch.set_num_threads(num_threads)\n",
    "\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.version.cuda)\n",
    "print(torch._C._cuda_getCompiledVersion(), \"cuda compiled version\")\n",
    "print(torchvision.__version__, \"Torchvision version\")\n",
    "print(\"Torch version\", torch.__version__)\n",
    "print(torch.cuda.get_arch_list())\n",
    "\n",
    "print(torch.cuda.nccl.version())\n",
    "print(\"Are GPUS available\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['NCCL_P2P_DISABLE'] = '1'\n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models.video\n",
    "\n",
    "## CHANGE THIS\n",
    "dir2 = os.path.abspath(\"/volume/Orion/orion\")\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path:\n",
    "    sys.path.append(dir1)\n",
    "import importlib\n",
    "\n",
    "importlib.util.find_spec(\"orion\")\n",
    "\n",
    "from orion.models import movinet, pyvid_multiclass_x3d, stam, timesformer, vivit, x3d, x3d_multi\n",
    "\n",
    "model = x3d(num_classes=10, task=\"regression\")\n",
    "display(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os\n",
    "df = pd.read_csv(\n",
    "    \"/volume/Orion/data/train_val_test_LCA_REGRESSION_with_MHI_2021_data_new_mu.csv\",\n",
    "    sep=\"µ\",\n",
    ")\n",
    "df['y_true_cat'] = np.where(df['Value'] < 40.00, 1, 0)\n",
    "df['FileName'] = df['FileName'].str.replace('/volume/Orion/exported_videos_512_by_512_MHI_UCSF/', '/media/data1/ravram/exported_videos_512_by_512_MHI_UCSF/')\n",
    "#df = df.sample(100)\n",
    "#df.to_csv('/volume/Orion/data/train_val_test_LCA_REGRESSION_with_MHI_2021_data_new_small_mu.csv', sep=\"µ\")\n",
    "for file_name in df['FileName']:\n",
    "    if os.path.exists(file_name):\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"{file_name} does not exist\")\n",
    "\n",
    "df.to_csv('../../../Orion/data/train_val_test_LCA_REGRESSION_with_MHI_2021_data_NAS_path_mu.csv', sep=\"µ\")\n",
    "\n",
    "#file_name = \"/volume/Orion/exported_videos_512_by_512_MHI_UCSF/66661628_2469453.dcm.avi\"\n",
    "#split = df.loc[df['FileName'] == file_name, 'Split'].values[0]\n",
    "#print(split)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Load /volume/Orion/data/train_val_test_LCA_REGRESSION_with_MHI_2021_data_15_FPS_only_exclude_outliers_mu.csv with mu separator\n",
    "#df = pd.read_csv(\n",
    "#    \"/volume/Orion/data/train_val_test_LCA_REGRESSION_with_MHI_2021_data_15_FPS_only_exclude_outliers_mu.csv\",\n",
    "#    sep=\"µ\",\n",
    "#)\n",
    "#display(df.Value.describe())\n",
    "#display(df.FileName)\n",
    "\n",
    "def min_max_scaling(value, min_val=10, max_val=74.9):\n",
    "    \"\"\"\n",
    "    Apply min-max scaling to a given value.\n",
    "\n",
    "    Parameters:\n",
    "    value (float): The value to be scaled.\n",
    "    min_val (float): The minimum value of the original range.\n",
    "    max_val (float): The maximum value of the original range.\n",
    "\n",
    "    Returns:\n",
    "    float: The scaled value.\n",
    "    \"\"\"\n",
    "    return (value - min_val) / (max_val - min_val)\n",
    "\n",
    "# Example usage\n",
    "#df['Value_min_max'] = min_max_scaling(df['Value'])\n",
    "#display(df['Value_min_max'].describe())\n",
    "\n",
    "#df.to_csv(\n",
    "#    \"/volume/Orion/data/train_val_test_LCA_REGRESSION_with_MHI_2021_data_15_FPS_only_exclude_outliers_min_maxmu.csv\",\n",
    "#    sep=\"µ\",\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import orion.utils as utils\n",
    "display(utils.loadvideo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from orion.utils import video_regress_ddp\n",
    "from orion.utils import video_training_and_eval\n",
    "import wandb\n",
    "import yaml\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"test_view_classifier.ipynb\"\n",
    "# Set environment variables for 'env://' initialization\n",
    "os.environ['RANK'] = '0'\n",
    "os.environ['WORLD_SIZE'] = '1'\n",
    "os.environ['MASTER_ADDR'] = 'localhost'\n",
    "os.environ['MASTER_PORT'] = '12355'  # Use an open port\n",
    "\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.local_rank = 0  # Set default values as needed\n",
    "        self.log_all = False\n",
    "        self.epochs = 2\n",
    "        self.batch = 32\n",
    "\n",
    "\n",
    "# Create an instance of Args\n",
    "args = Args()\n",
    "\n",
    "# Load configuration from YAML file\n",
    "with open('config/config.yaml', 'r') as file:\n",
    "    config_defaults = yaml.safe_load(file)\n",
    "# Create the transforms\n",
    "transform_list = video_training_and_eval.create_transforms(config_defaults)\n",
    "\n",
    "# Initialize a wandb run if logging, otherwise return None\n",
    "run = video_training_and_eval.setup_run(args, config_defaults)\n",
    "# Run the main process\n",
    "video_training_and_eval.execute_run(config_defaults=config_defaults, transforms=transform_list, args=args, run=run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    \"name\": \"1_CathEF_UCSF_MHI_2021_Retrain_15_fps_3\",\n",
    "    \"model_name\": {\"values\": [\"x3d\"]},\n",
    "    \"method\": \"bayes\",  # grid, random\n",
    "    # \"metric\": {\"name\": \"best_val_auc\", \"goal\": \"maximize\"},\n",
    "    \"metric\": {\"name\": \"best_val_loss\", \"goal\": \"minimize\"},\n",
    "    \"parameters\": {\n",
    "        \"lr\": {\n",
    "            \"distribution\": \"uniform\",\n",
    "            \"min\": 1e-5,\n",
    "            \"max\": 1e-3,\n",
    "        },\n",
    "        \"rand_augment\": {\"values\": [True, False]},\n",
    "        \"loss\": {\"values\": [\"l1_loss\"]},\n",
    "        \"optimizer\": {\"values\": [\"SGD\", \"Adam\", \"RAdam\"]},\n",
    "        \"patience\": {\"min\": 10, \"max\": 20},\n",
    "        \"factor\": {\"values\": [0.3, 0.5]},\n",
    "        \"frames\": {\"values\": [48, 60, 72]},\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 15  # number of runs to execute\n",
    "wandb.agent(\n",
    "    sweep_id=sweep_id,\n",
    "    function=lambda: video_regress.run(\n",
    "        config_defaults,\n",
    "        tag=config_defaults[\"tag\"],\n",
    "        wandb_project=config_defaults[\"project\"],\n",
    "        transforms=config_defaults[\"transforms\"],\n",
    "    ),\n",
    "    count=count,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot predictions for sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import os\n",
    "import os\n",
    "import sys\n",
    "\n",
    "## CHANGE THIS\n",
    "dir2 = os.path.abspath(\"/volume|/Orion/orion\")\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path:\n",
    "    sys.path.append(dir1)\n",
    "import importlib\n",
    "\n",
    "importlib.util.find_spec(\"orion\")\n",
    "# import torch\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.core.display import HTML, display\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "pd.set_option(\"display.max_columns\", 250)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "pd.set_option(\"display.max_colwidth\", 300)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "dir2 = os.path.abspath(\"/volume/DicomVideoProcessing/downloadAvi/\")\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path:\n",
    "    sys.path.append(dir1)\n",
    "import importlib\n",
    "\n",
    "importlib.util.find_spec(\"downloadAvi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from downloadAvi import plot_avi as plot_avi\n",
    "df_predictions = pd.read_csv('../trained_models/swin3d_s_2_24_1_RAdam_new_20231222-154107/test_predictions.csv')\n",
    "df_predictions = df_predictions.rename(columns={'filename': 'FileName'})\n",
    "\n",
    "class_mapping = {\n",
    "    0: \"Aorta\",\n",
    "    1: \"Catheter\",\n",
    "    2: \"Femoral\",\n",
    "    3: \"Graft\",\n",
    "    4: \"LV\",\n",
    "    5: \"Left\",\n",
    "    6: \"Other\",\n",
    "    7: \"Pigtail\",\n",
    "    8: \"Radial\",\n",
    "    9: \"Right\",\n",
    "    10: \"Stenting\"\n",
    "}\n",
    "\n",
    "def get_predicted_class(prob_string):\n",
    "    prob_array = np.array([float(num) for num in prob_string.strip(\"[]\").split()])\n",
    "    predicted_class = np.argmax(prob_array)\n",
    "    return predicted_class, class_mapping[predicted_class]\n",
    "\n",
    "# Apply the function to each row in the 'y_pred' column\n",
    "df_predictions[['y_pred', 'predicted_class']] = df_predictions['y_hat'].apply(get_predicted_class).apply(pd.Series)\n",
    "\n",
    "df_predictions['y_true_mapped'] = df_predictions['y_true'].map(class_mapping)\n",
    "\n",
    "#print(df_predictions.head(n=25))\n",
    "# Example usage\n",
    "# Assuming your DataFrame is named df\n",
    "plot_avi.sample_and_plot_middle_frames(df_predictions, N=15, label_column='y_true_mapped', second_label_column='predicted_class')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatched_instances = df_predictions[df_predictions['y_true'] != df_predictions['y_pred']]\n",
    "print(len(mismatched_instances))\n",
    "# Assuming your DataFrame is named df\n",
    "plot_avi.sample_and_plot_middle_frames(mismatched_instances, N=25, label_column='y_true_mapped', second_label_column='predicted_class')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "## Load  /volume/Orion/data/DeepCORO_ALGO1_ObjectRecong_with_CathEF_UCSF_MHI_dataset_train_test_dev_NAS_path_mu.csv\n",
    "df = pd.read_csv('/volume/Orion/data/DeepCORO_ALGO1_ObjectRecong_with_CathEF_UCSF_MHI_dataset_train_test_dev_NAS_path_mu.csv', sep='µ')\n",
    "display(df.head(n=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find how manydf['FileName'] is in df_predictions['FileName']\n",
    "display(df.loc[df['FileName'].isin(df_predictions['FileName'])].Split.value_counts())\n",
    "display(df['FileName'].isin(df_predictions['FileName']).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
